{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6nP++UWwCjAGttw3pGmdn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoxiang66/CS-285-at-UC-Berkeley-Deep-Reinforcement-Learning-2021/blob/main/examples/A2C_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/leoxiang66/CS-285-at-UC-Berkeley-Deep-Reinforcement-Learning-2021.git"
      ],
      "metadata": {
        "id": "Ous8z7fILdIB",
        "outputId": "0eacd7b2-8d1d-4ae6-e17d-f2494612d814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/leoxiang66/CS-285-at-UC-Berkeley-Deep-Reinforcement-Learning-2021.git\n",
            "  Cloning https://github.com/leoxiang66/CS-285-at-UC-Berkeley-Deep-Reinforcement-Learning-2021.git to /tmp/pip-req-build-7vjrrevq\n",
            "  Running command git clone -q https://github.com/leoxiang66/CS-285-at-UC-Berkeley-Deep-Reinforcement-Learning-2021.git /tmp/pip-req-build-7vjrrevq\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from RLalgos==0.1.3) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from RLalgos==0.1.3) (1.21.6)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from RLalgos==0.1.3) (0.25.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym->RLalgos==0.1.3) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym->RLalgos==0.1.3) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->RLalgos==0.1.3) (1.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->RLalgos==0.1.3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->RLalgos==0.1.3) (3.8.1)\n",
            "Building wheels for collected packages: RLalgos\n",
            "  Building wheel for RLalgos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for RLalgos: filename=RLalgos-0.1.3-py3-none-any.whl size=8155 sha256=2a8d34d7a6e627756961d7018c805271f962e2fc49266bfe8e4846eedf4a8175\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-osy8fsrz/wheels/4c/56/f2/8ddd79049992cb6f5396813f1f0ab97eac7ab2633c7c9eb79d\n",
            "Successfully built RLalgos\n",
            "Installing collected packages: RLalgos\n",
            "Successfully installed RLalgos-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from RLalgos import A2C as A2CAgent"
      ],
      "metadata": {
        "id": "1PXn-z6pLo-r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "from collections import deque\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wUWOoHdKXkXS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Config A2C {display-mode: \"form\", run: \"auto\"}\n",
        "from pprint import pprint\n",
        "env_id = 'CartPole-v1'  #@param [\"CartPole-v1\", \"Acrobot-v1\", \"MountainCar-v0\"]\n",
        "value_learning_rate = 0.001  #@param {type: \"number\"}\n",
        "actor_learning_rate = 0.001  #@param {type: \"number\"}\n",
        "gamma = 1  #@param {type: \"number\"}\n",
        "entropy = 1  #@param {type: \"number\"}\n",
        "seed = 1  #@param {type: \"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "config_a2c = {\n",
        "    'env_id': env_id,\n",
        "    'gamma': gamma,\n",
        "    'seed': seed,\n",
        "    'value_network': {'learning_rate': value_learning_rate},\n",
        "    'actor_network': {'learning_rate': actor_learning_rate},\n",
        "    'entropy': entropy\n",
        "}\n",
        "\n",
        "print(\"Current config_a2c is:\")\n",
        "pprint(config_a2c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8vvjG9KX0rN",
        "outputId": "23e0232f-abee-48c2-dfa6-874e6c4b6967"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current config_a2c is:\n",
            "{'actor_network': {'learning_rate': 0.001},\n",
            " 'entropy': 1,\n",
            " 'env_id': 'CartPole-v1',\n",
            " 'gamma': 1,\n",
            " 'seed': 1,\n",
            " 'value_network': {'learning_rate': 0.001}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = A2CAgent(config_a2c)\n",
        "rewards = agent.training_batch(1000, 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwbbbYMlYU5j",
        "outputId": "78e2c8cc-6199-4b4c-e384-13314f89e2b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:257: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  \"Function `env.seed(seed)` is marked as deprecated and will be removed in the future. \"\n",
            "/usr/local/lib/python3.7/dist-packages/RLalgos/A2C.py:107: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  actions = np.empty((batch_size,), dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/RLalgos/A2C.py:108: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dones = np.empty((batch_size,), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/RLalgos/A2C.py:109: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  rewards, values = np.empty((2, batch_size), dtype=np.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1000: Mean rewards: 22.64, Std: 11.85\n",
            "Epoch 50/1000: Mean rewards: 37.08, Std: 20.54\n",
            "Epoch 100/1000: Mean rewards: 64.68, Std: 41.18\n",
            "Epoch 150/1000: Mean rewards: 82.0, Std: 44.5\n",
            "Epoch 200/1000: Mean rewards: 182.94, Std: 87.27\n",
            "Epoch 250/1000: Mean rewards: 218.14, Std: 85.63\n",
            "Epoch 300/1000: Mean rewards: 291.76, Std: 127.34\n",
            "Epoch 350/1000: Mean rewards: 348.24, Std: 133.85\n",
            "Epoch 400/1000: Mean rewards: 404.06, Std: 119.66\n",
            "Epoch 450/1000: Mean rewards: 376.48, Std: 102.97\n",
            "Epoch 500/1000: Mean rewards: 463.82, Std: 78.56\n",
            "Epoch 550/1000: Mean rewards: 409.14, Std: 96.66\n",
            "Epoch 600/1000: Mean rewards: 474.84, Std: 56.25\n",
            "Epoch 650/1000: Mean rewards: 457.72, Std: 87.65\n",
            "Epoch 700/1000: Mean rewards: 429.46, Std: 99.18\n",
            "Epoch 750/1000: Mean rewards: 489.18, Std: 47.07\n",
            "Epoch 800/1000: Mean rewards: 428.58, Std: 90.44\n",
            "Epoch 850/1000: Mean rewards: 478.78, Std: 69.87\n",
            "Epoch 900/1000: Mean rewards: 476.58, Std: 78.6\n",
            "Epoch 950/1000: Mean rewards: 476.48, Std: 75.73\n",
            "Epoch 999/1000: Mean rewards: 496.24, Std: 24.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdHQXBf_YYfu",
        "outputId": "759412bc-3942-4f85-812b-40d165fa154e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}